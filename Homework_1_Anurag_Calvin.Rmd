---
title: "Homework Assignment 1"
subtitle: "Jumpstart to RMarkdown"
author:
  - Anurag Amin^[<anurag.amin@uconn.edu>; M.S. student at
    Department of Mathematics, University of Connecticut.]
  - Calvin Jackson^[<calvin.jackson@uconn.edu>; M.S. student at
    Department of Mathematics, University of Connecticut.]
date: "`r format(Sys.time(), '%d %B %Y')`"
documentclass: article
papersize: letter
fontsize: 11pt
bibliography: template.bib
biblio-style: datalab
keywords: Monte Carlo methods, Normal distribution, simulation.
output:
  bookdown::pdf_document2
  bookdown::html_document2
abstract: |
  In this assignment we will be approximating the cumulative distribution function for a standard normal random variable using Monte Carlo methods. These simulations will be done at various sample sizes to estimate predetermined values and gauge the rate at which accuracy increases with sample size and other trends of interest.
---


```{r setup, echo = FALSE, message = FALSE, warning = FALSE}
source("utils_template.R")

## We will need "bookdown" & "reticulate" packages for this project.
pkgs <- c("splines2", "DT", "webshot", "leaflet", "bookdown", "reticulate")
need.packages(pkgs)
outFormat <- knitr::opts_knit$get("rmarkdown.pandoc.to")
isHtml <- identical(outFormat, "html")
isLatex <- identical(outFormat, "latex")
latex <- ifelse(isLatex, '\\LaTeX\\', 'LaTeX')
knitr::opts_chunk$set(fig.width = 5, fig.height = 4, dpi = 300,
                      out.width = "90%", fig.align = "center")
```
  
# Introduction {#sec:intro}
  
  In this project, our end goal is to test the effectiveness of Monte Carlo estimation of the cumulative distribution function of a standard normal variable. We test to see how the effectiveness varies with different sample size by running three different sample sizes a hundred times each. We also test the accuracy of the estimation at 9 different input values to see if the t value impacts the accuracy of the estimator.\\
  We do this with the intent to generate 27 box plots, one corresponding to each possible combination of n and t value to visually observe the trends of interest.
  
# Procedure {#sec:procedure}

  First, we calculate the value of the cumulative distribution function using Monte Carlo estimation. We do this by first generating a string of n random draws from a standard normal distribution and running a function which counts the number of these n elements which are less than or equal to our t value. This number divided by out total n number represents our Monte Carlo estimate. This last output is equivalent to the following estimation equation: 

\begin{align}
\widehat{\Phi}(t) = \frac{1}{n} \sum\limits_{i=1}^n I(X_{i}\leq t)
\end{align}

  Now that we have a flexible function which can be run using any n and t values, we run it a 100 times for each of our n values on each of the t values. The correct answer we are benchmarking our estimate against is of the following form:
  
\begin{align}
\Phi(t) = \int_{-\infty}^{t} \frac{1}{\sqrt{2\pi}} e^\frac{-y^2}{2} dy
\end{align}

  We now plot all calculated values on to a box plot to visualise the spread or bias in each case, i.e. for different number of draws (100, 1000, 10000) for every t value.
  
  For each draw, we measure the absolute value of the difference between the true integral value and the Monte Carlo estimation and record these values in a table. Because it would be impractical to show all 100 repetitions of our 27 scenarios, we report 1 such value per case to illustrate the format of our underlying dataset used to generate our box plot.
  
# Table {#sec:table}


```{r Comparison, echo = FALSE}
#source("Comparison Table.R")
Bias <- function(simulation_no, t) {
    random_generated_values <- rnorm(simulation_no)
    random_values_lt_t <- random_generated_values[random_generated_values <= 
        t]
    number_satisfying <- length(random_values_lt_t)
    cdf_approx <- number_satisfying/simulation_no
    bias <- cdf_approx - pnorm(t, 0, 1)
    return(bias)
}

data_gen <- function(t_values, simulation_values) {
    table_of_values <- data.frame()
    
    for (t in t_values) {
        for (simulation_no in simulation_values) {
            for (p in 1:1) {
                temp <- Bias(simulation_no, t)
                table_of_values <- rbind(table_of_values, c(t, simulation_no, 
                  temp + pnorm(t, 0, 1), pnorm(t, 0, 1), abs(temp)))
            }
        }
    }
    colnames(table_of_values) <- c("t value", "No of simulations", "Approximated Value", 
        "True Value", "Bias")
    return(table_of_values)
}

proj_t_values <- c(0, 0.67, 0.84, 1.28, 1.65, 2.32, 2.58, 3.09, 3.72)
proj_simulation_values <- c(100, 1000, 10000)

table <- data_gen(proj_t_values, proj_simulation_values)
knitr::kable(table)
```

# Plots {#sec:plot}


```{r boxplot, echo = FALSE, fig.width = 8}
#source("Bias.R")
Bias <- function(simulation_no, t) {
    random_generated_values <- rnorm(simulation_no)
    random_values_lt_t <- random_generated_values[random_generated_values <= 
        t]
    number_satisfying <- length(random_values_lt_t)
    cdf_approx <- number_satisfying/simulation_no
    bias <- abs(cdf_approx - pnorm(t, 0, 1))
    return(bias)
}

data_gen <- function(t_values, simulation_values) {
    table_of_values <- data.frame()
    
    for (t in t_values) {
        for (simulation_no in simulation_values) {
            for (p in 1:100) {
                temp <- Bias(simulation_no, t)
                table_of_values <- rbind(table_of_values, c(t, simulation_no, 
                  p, temp))
            }
        }
    }
    colnames(table_of_values) <- c("t_value", "no_of_simulations", "replication_no", 
        "Bias")
    return(table_of_values)
}

proj_t_values <- c(0, 0.67, 0.84, 1.28, 1.65, 2.32, 2.58, 3.09, 3.72)
proj_simulation_value1 <- c(100)
proj_simulation_value2 <- c(1000)
proj_simulation_value3 <- c(10000)
# proj_simulation_values <- c(100,1000,10000)

table1 <- data_gen(proj_t_values, proj_simulation_value1)
boxplot(Bias ~ t_value, data = table1, ylab = "Bias", xlab = "t values", 
    main = "Bias Plot for n = 100")
table2 <- data_gen(proj_t_values, proj_simulation_value2)
boxplot(Bias ~ t_value, data = table2, ylab = "Bias", xlab = "t values", 
    main = "Bias Plot for n = 1000")
table3 <- data_gen(proj_t_values, proj_simulation_value3)
boxplot(Bias ~ t_value, data = table3, ylab = "Bias", xlab = "t values", 
    main = "Bias Plot for n = 10000")
```

# Code Chunk {#sec:code}


```{r eval=FALSE}
# This is the code chunk used to create the table for our work
Bias <- function(simulation_no, t) {
    random_generated_values <- rnorm(simulation_no)
    random_values_lt_t <- random_generated_values[random_generated_values <= 
        t]
    number_satisfying <- length(random_values_lt_t)
    cdf_approx <- number_satisfying/simulation_no
    bias <- cdf_approx - pnorm(t, 0, 1)
    return(bias)
}

data_gen <- function(t_values, simulation_values) {
    table_of_values <- data.frame()
    
    for (t in t_values) {
        for (simulation_no in simulation_values) {
            for (p in 1:1) {
                temp <- Bias(simulation_no, t)
                table_of_values <- rbind(table_of_values, c(t, simulation_no, 
                  temp + pnorm(t, 0, 1), pnorm(t, 0, 1), abs(temp)))
            }
        }
    }
    colnames(table_of_values) <- c("t value", "No of simulations", "Approximated Value", 
        "True Value", "Bias")
    return(table_of_values)
}

proj_t_values <- c(0, 0.67, 0.84, 1.28, 1.65, 2.32, 2.58, 3.09, 3.72)
proj_simulation_values <- c(100, 1000, 10000)

table <- data_gen(proj_t_values, proj_simulation_values)
knitr::kable(table)
```

# Summary and Discussion {#sec:summary}

  From this plot, we see that both, an increase in t from 0 and an increase in n, both lead to decreases of the spread in the estimation around the true values. We see that the increase in accuracy is most pronounced when increasing t from the smallest values. Moreover, there does not appear to be any t value where a lower sample size outperforms a higher sample size. This graphically illustrates that if we were to continue increasing n and t indefinitely, we could trap all the estimation values in an open interval around the true value which converges on either side to the true value. We suspect that, if you were to decrease the t value below 0, the accuracy would actually increase as we decrease t. We make this inference from the symmetric quality of the normal distribution.